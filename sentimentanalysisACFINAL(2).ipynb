{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import numpy as np\n",
    "# dataframe functions\n",
    "from pyspark.sql import functions as fn\n",
    "from __future__ import division\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "# we obtain the stop words from a website\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "stop_words[0:10]\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import seaborn\n",
    "from pyspark.ml import feature\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.append('https')\n",
    "stop_words.append('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##turning polarity into stretched 0-5 scrores\n",
    "\n",
    "#new = int((old + 1) * 2.999999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can create intensity scores from polarity but the issue then is how do we make a log of that,\n",
    "#next best thing is to create more classses and then look at statistical differences from those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenario 1: turn all scores into positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDFP=pd.read_csv('fulldatasetT.csv',dtype={'polarity': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDFP=fullDFP.loc[:,['id','text','place','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDFP['score']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.loc[data_df[\"mean radius\"] > 12.0, \"mean radius\"] = 0\n",
    "fullDFP.loc[fullDFP[\"polarity\"] > 0.0, 'score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.29E+18</td>\n",
       "      <td>Yoga Instructorüßò‚Äç‚ôÄÔ∏è @bare_table rocks it Frida...</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29E+18</td>\n",
       "      <td>Coz a nice stroll in the city is like a ghost ...</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.29E+18</td>\n",
       "      <td>NEW! #Facemasks in my Society6 #Shop üëâ https:/...</td>\n",
       "      <td>Martinique</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.29E+18</td>\n",
       "      <td>I‚Äôm not saying I‚Äôm bored, but I have invented ...</td>\n",
       "      <td>Boise, ID</td>\n",
       "      <td>-0.1356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.29E+18</td>\n",
       "      <td>Fighting Stigma: NPHET discuss regional lockdo...</td>\n",
       "      <td>Mascouche, Qu√©bec</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151575</th>\n",
       "      <td>1.37E+18</td>\n",
       "      <td>Call us. We‚Äôll keep you safe. Always wear a ma...</td>\n",
       "      <td>Boca Raton, FL</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151576</th>\n",
       "      <td>1.37E+18</td>\n",
       "      <td>What is #themoment you knew the pandemic was c...</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>-0.1519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151577</th>\n",
       "      <td>1.37E+18</td>\n",
       "      <td>I‚Äôve had just about every post-vaccine side ef...</td>\n",
       "      <td>Sapulpa, OK</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151578</th>\n",
       "      <td>1.37E+18</td>\n",
       "      <td>Updated: Closure on #SouthernStateParkway EB a...</td>\n",
       "      <td>North Valley Stream, NY</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151579</th>\n",
       "      <td>1.37E+18</td>\n",
       "      <td>Updated: Closure on #SouthernStateParkway EB a...</td>\n",
       "      <td>North Valley Stream, NY</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151580 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  \\\n",
       "0       1.29E+18  Yoga Instructorüßò‚Äç‚ôÄÔ∏è @bare_table rocks it Frida...   \n",
       "1       1.29E+18  Coz a nice stroll in the city is like a ghost ...   \n",
       "2       1.29E+18  NEW! #Facemasks in my Society6 #Shop üëâ https:/...   \n",
       "3       1.29E+18  I‚Äôm not saying I‚Äôm bored, but I have invented ...   \n",
       "4       1.29E+18  Fighting Stigma: NPHET discuss regional lockdo...   \n",
       "...          ...                                                ...   \n",
       "151575  1.37E+18  Call us. We‚Äôll keep you safe. Always wear a ma...   \n",
       "151576  1.37E+18  What is #themoment you knew the pandemic was c...   \n",
       "151577  1.37E+18  I‚Äôve had just about every post-vaccine side ef...   \n",
       "151578  1.37E+18  Updated: Closure on #SouthernStateParkway EB a...   \n",
       "151579  1.37E+18  Updated: Closure on #SouthernStateParkway EB a...   \n",
       "\n",
       "                          place  polarity  score  \n",
       "0                 Kentucky, USA    0.1767      1  \n",
       "1       Sydney, New South Wales    0.3333      1  \n",
       "2                    Martinique    0.1705      1  \n",
       "3                     Boise, ID   -0.1356      0  \n",
       "4             Mascouche, Qu√©bec    0.0000      0  \n",
       "...                         ...       ...    ...  \n",
       "151575           Boca Raton, FL    0.5000      1  \n",
       "151576            Manhattan, NY   -0.1519      0  \n",
       "151577              Sapulpa, OK    0.0958      1  \n",
       "151578  North Valley Stream, NY    0.0000      0  \n",
       "151579  North Valley Stream, NY    0.0000      0  \n",
       "\n",
       "[151580 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "mySchema = StructType([StructField(\"id\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"text\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"place\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"polarity\", FloatType(), True)\\\n",
    "                       \n",
    "                       ,StructField(\"score\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDf=spark.createDataFrame(fullDFP,schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------+-----+\n",
      "|      id|                text|               place|polarity|score|\n",
      "+--------+--------------------+--------------------+--------+-----+\n",
      "|1.29E+18|Yoga Instructorüßò...|       Kentucky, USA|  0.1767|    1|\n",
      "|1.29E+18|Coz a nice stroll...|Sydney, New South...|  0.3333|    1|\n",
      "|1.29E+18|NEW! #Facemasks i...|          Martinique|  0.1705|    1|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, Qu√©bec|  0.1238|    1|\n",
      "|1.29E+18|BON APPETITE\n",
      "\n",
      "Eva...|     Bal Harbour, FL|  0.0111|    1|\n",
      "|1.29E+18|We are probably m...|      Tennessee, USA|  0.0606|    1|\n",
      "|1.29E+18|Great #summer nig...|        Pasadena, CA|     0.6|    1|\n",
      "|1.29E+18|Waited all day to...|         Phoenix, AZ|  0.2964|    1|\n",
      "|1.29E+18|Another new month...|  Navi Mumbai, India|  0.1811|    1|\n",
      "|1.29E+18|@ChelseaFC\n",
      "\n",
      "let's...|       Ogun, Nigeria|     0.5|    1|\n",
      "+--------+--------------------+--------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullDf.where(fn.col('score')==1).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews_df = spark.read.parquet('imdb_reviews_preprocessed.parquet')\n",
    "sentiments_df=spark.read.parquet('sentiments.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer().setGaps(False)\\\n",
    "  .setPattern(\"\\\\p{L}+\")\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"words\")\n",
    "review_words_df = tokenizer.transform(fullDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------+-----+--------------------+\n",
      "|      id|                text|               place|polarity|score|               words|\n",
      "+--------+--------------------+--------------------+--------+-----+--------------------+\n",
      "|1.29E+18|Yoga Instructorüßò...|       Kentucky, USA|  0.1767|    1|[yoga, instructor...|\n",
      "|1.29E+18|Coz a nice stroll...|Sydney, New South...|  0.3333|    1|[coz, a, nice, st...|\n",
      "|1.29E+18|NEW! #Facemasks i...|          Martinique|  0.1705|    1|[new, facemasks, ...|\n",
      "|1.29E+18|I‚Äôm not saying I‚Äô...|           Boise, ID| -0.1356|    0|[i, m, not, sayin...|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, Qu√©bec|     0.0|    0|[fighting, stigma...|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, Qu√©bec| -0.3125|    0|[fighting, stigma...|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, Qu√©bec|  0.1238|    1|[fighting, stigma...|\n",
      "|1.29E+18|Them COVID nights...|Vandenberg Villag...|     0.0|    0|[them, covid, nig...|\n",
      "|1.29E+18|Shoot after post ...|Fort Tondiarpet, ...|     0.0|    0|[shoot, after, po...|\n",
      "|1.29E+18|BON APPETITE\n",
      "\n",
      "Eva...|     Bal Harbour, FL|  0.0111|    1|[bon, appetite, e...|\n",
      "|1.29E+18|Been trying to ma...|       Southport, IN| -0.0429|    0|[been, trying, to...|\n",
      "|1.29E+18|Been trying to ma...|       Southport, IN| -0.0429|    0|[been, trying, to...|\n",
      "|1.29E+18|We are probably m...|      Tennessee, USA|  0.0606|    1|[we, are, probabl...|\n",
      "|1.29E+18|Great #summer nig...|        Pasadena, CA|     0.6|    1|[great, summer, n...|\n",
      "|1.29E+18|Waited all day to...|         Phoenix, AZ|  0.2964|    1|[waited, all, day...|\n",
      "|1.29E+18|Another new month...|  Navi Mumbai, India|  0.1811|    1|[another, new, mo...|\n",
      "|1.29E+18|@ChelseaFC\n",
      "\n",
      "let's...|       Ogun, Nigeria|     0.5|    1|[chelseafc, let, ...|\n",
      "|1.29E+18|Before lockdown\n",
      "....|        Sagar, India|     0.0|    0|[before, lockdown...|\n",
      "|1.29E+18|My Mamang pogi......|Manila City, Nati...|  0.0982|    1|[my, mamang, pogi...|\n",
      "|1.29E+18|Evening in Santa ...|      Santa Cruz, CA|     0.0|    0|[evening, in, san...|\n",
      "+--------+--------------------+--------------------+--------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_words_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+\n",
      "|      word|      id|sentiment|\n",
      "+----------+--------+---------+\n",
      "|confidence|1.29E+18|        1|\n",
      "|    strong|1.29E+18|        1|\n",
      "|      nice|1.29E+18|        1|\n",
      "|      like|1.29E+18|        1|\n",
      "|protection|1.29E+18|        1|\n",
      "+----------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_words_sentiment_df = review_words_df.\\\n",
    "    select('id', fn.explode('words').alias('word')).\\\n",
    "    join(sentiments_df, 'word')\n",
    "tweet_words_sentiment_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------+\n",
      "|      id|      avg_sentiment|predicted|\n",
      "+--------+-------------------+---------+\n",
      "|1.31E+18|0.13998100664767332|      1.0|\n",
      "|1.32E+18| 0.1479426096372496|      1.0|\n",
      "|1.30E+18| 0.3137938922566625|      1.0|\n",
      "|1.36E+18|0.12607260726072608|      1.0|\n",
      "|1.37E+18|0.22395476353666896|      1.0|\n",
      "+--------+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_sentiment_prediction_df = tweet_words_sentiment_df.\\\n",
    "    groupBy('id').\\\n",
    "    agg(fn.avg('sentiment').alias('avg_sentiment')).\\\n",
    "    withColumn('predicted', fn.when(fn.col('avg_sentiment') > 0, 1.0).otherwise(0.))\n",
    "simple_sentiment_prediction_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.5745594648264578|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullDf.\\\n",
    "    join(simple_sentiment_prediction_df, 'id').\\\n",
    "    select(fn.expr('float(score = predicted)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, text: string, place: string, polarity: float, score: int, words: array<string>, filtered: array<string>, tf: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered\")\n",
    "\n",
    "# we will remove words that appear in 5 docs or less\n",
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered\")\\\n",
    "  .setOutputCol(\"tf\")\n",
    "\n",
    "\n",
    "# we now create a pipelined transformer\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(fullDf)\n",
    "# now we can make the transformation between the raw text and the counts\n",
    "cv_pipeline.transform(fullDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31661"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_pipeline.stages[-1].vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('score').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)\n",
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(fullDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = fullDf.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline(stages=[idf_pipeline, lr]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.7767307395228742|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline.transform(validation_df).\\\n",
    "    select(fn.expr('float(prediction = score)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = idf_pipeline.stages[0].stages[-1].vocabulary\n",
    "weights = lr_pipeline.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>devastating</td>\n",
       "      <td>-24.353693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27348</th>\n",
       "      <td>hapiness</td>\n",
       "      <td>-22.054723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>awful</td>\n",
       "      <td>-21.530582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28815</th>\n",
       "      <td>shutterstock</td>\n",
       "      <td>-20.263581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23952</th>\n",
       "      <td>crooked</td>\n",
       "      <td>-19.802672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28689</th>\n",
       "      <td>burdens</td>\n",
       "      <td>-19.573643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20776</th>\n",
       "      <td>forecasting</td>\n",
       "      <td>-18.849654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17144</th>\n",
       "      <td>turtles</td>\n",
       "      <td>-18.692263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>terrifying</td>\n",
       "      <td>-18.420199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14858</th>\n",
       "      <td>fearful</td>\n",
       "      <td>-18.305814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word     weight\n",
       "5241    devastating -24.353693\n",
       "27348      hapiness -22.054723\n",
       "5057          awful -21.530582\n",
       "28815  shutterstock -20.263581\n",
       "23952       crooked -19.802672\n",
       "28689       burdens -19.573643\n",
       "20776   forecasting -18.849654\n",
       "17144       turtles -18.692263\n",
       "10741    terrifying -18.420199\n",
       "14858       fearful -18.305814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_df.sort_values('weight').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_par = 0.02\n",
    "alpha_par = 0.3\n",
    "en_lr = LogisticRegression().\\\n",
    "        setLabelCol('score').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(lambda_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(alpha_par)\n",
    "en_lr_estimator = Pipeline(\n",
    "    stages=[tokenizer, sw_filter, cv, idf, en_lr])\n",
    "en_lr_pipeline = en_lr_estimator.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|avg(float((prediction = score)))|\n",
      "+--------------------------------+\n",
      "|              0.8710965947961954|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_lr_pipeline.transform(validation_df).select(fn.avg(fn.expr('float(prediction = score)'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.201350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>hate</td>\n",
       "      <td>-0.182759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>crazy</td>\n",
       "      <td>-0.178315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>stupid</td>\n",
       "      <td>-0.170983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>sick</td>\n",
       "      <td>-0.170353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>cold</td>\n",
       "      <td>-0.165276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>soda</td>\n",
       "      <td>-0.162481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6824</th>\n",
       "      <td>goldkilos</td>\n",
       "      <td>-0.151609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>sad</td>\n",
       "      <td>-0.127827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>difficult</td>\n",
       "      <td>-0.126444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>wrong</td>\n",
       "      <td>-0.123174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>savetheworld</td>\n",
       "      <td>-0.117022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>streetphotographer</td>\n",
       "      <td>-0.112605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>chicken</td>\n",
       "      <td>-0.109292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word    weight\n",
       "1317               worst -0.218300\n",
       "443                  bad -0.201350\n",
       "1664                hate -0.182759\n",
       "496                crazy -0.178315\n",
       "2035              stupid -0.170983\n",
       "1134                sick -0.170353\n",
       "985                 cold -0.165276\n",
       "441                 soda -0.162481\n",
       "6824           goldkilos -0.151609\n",
       "996                  sad -0.127827\n",
       "782            difficult -0.126444\n",
       "1403               wrong -0.123174\n",
       "497         savetheworld -0.117022\n",
       "391   streetphotographer -0.112605\n",
       "1021             chicken -0.109292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_weights = en_lr_pipeline.stages[-1].coefficients.toArray()\n",
    "en_coeffs_df = pd.DataFrame({'word': en_lr_pipeline.stages[2].vocabulary, 'weight': en_weights})\n",
    "en_coeffs_df.sort_values('weight').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td>0.648823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.604511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>good</td>\n",
       "      <td>0.561014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>love</td>\n",
       "      <td>0.544115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>great</td>\n",
       "      <td>0.530618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>best</td>\n",
       "      <td>0.527535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>safe</td>\n",
       "      <td>0.512404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>0.476345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>free</td>\n",
       "      <td>0.417571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>available</td>\n",
       "      <td>0.409601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>latest</td>\n",
       "      <td>0.399358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>live</td>\n",
       "      <td>0.370560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.370140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>amazing</td>\n",
       "      <td>0.367577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>better</td>\n",
       "      <td>0.358128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    weight\n",
       "5          new  0.648823\n",
       "28       happy  0.604511\n",
       "32        good  0.561014\n",
       "25        love  0.544115\n",
       "39       great  0.530618\n",
       "88        best  0.527535\n",
       "29        safe  0.512404\n",
       "106  beautiful  0.476345\n",
       "92        free  0.417571\n",
       "146  available  0.409601\n",
       "256     latest  0.399358\n",
       "80        live  0.370560\n",
       "96      thanks  0.370140\n",
       "170    amazing  0.367577\n",
       "183     better  0.358128"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.sort_values('weight', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807051637978901"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.query('weight == 0.0').shape\n",
    "en_coeffs_df.query('weight == 0.0').shape[0]/en_coeffs_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>quarantine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>health</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stigma</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mask</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>just</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>like</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fighting</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>work</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ireland</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>socialdistancing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  weight\n",
       "0              covid     0.0\n",
       "4        coronavirus     0.0\n",
       "10              home     0.0\n",
       "11                 m     0.0\n",
       "13        quarantine     0.0\n",
       "14            health     0.0\n",
       "17            stigma     0.0\n",
       "18              mask     0.0\n",
       "20              just     0.0\n",
       "21              like     0.0\n",
       "22          fighting     0.0\n",
       "23              work     0.0\n",
       "24           ireland     0.0\n",
       "26  socialdistancing     0.0\n",
       "30                 d     0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.query('weight == 0.0').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n"
     ]
    }
   ],
   "source": [
    "grid = ParamGridBuilder().\\\n",
    "    addGrid(en_lr.regParam, [0., 0.01, 0.02]).\\\n",
    "    addGrid(en_lr.elasticNetParam, [0., 0.2, 0.4]).\\\n",
    "    build()\n",
    "all_models = []\n",
    "for j in range(len(grid)):\n",
    "    print(\"Fitting model {}\".format(j+1))\n",
    "    model = en_lr_estimator.fit(training_df, grid[j])\n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8185951051574604,\n",
       " 0.8185951051574604,\n",
       " 0.8185951051574604,\n",
       " 0.8496899344558957,\n",
       " 0.899499040010593,\n",
       " 0.8864122878644097,\n",
       " 0.8480568490278728,\n",
       " 0.8866109063624126,\n",
       " 0.8571270937699997]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate the accuracy of each of them:\n",
    "accuracies = [m.\\\n",
    "    transform(validation_df).\\\n",
    "    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n",
    "    first().\\\n",
    "    accuracy for m in all_models]\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_idx = np.argmax(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_5a34156cb995', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       " Param(parent='LogisticRegression_5a34156cb995', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          accuracy|\n",
      "+------------------+\n",
      "|0.9022833453971179|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = all_models[best_model_idx]\n",
    "# estimate generalization performance\n",
    "best_model.\\\n",
    "    transform(testing_df).\\\n",
    "    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEC corpus as input for the Best LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Equity Evaluation Corpus to use as testing data\n",
    "eec =pd.read_csv('Equity-Evaluation-Corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Template</th>\n",
       "      <th>Person</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-En-mystery-05498</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-En-mystery-11722</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>furious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-En-mystery-11364</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>irritated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-En-mystery-14320</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>enraged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-En-mystery-14114</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>annoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>2018-En-mystery-12020</td>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>2018-En-mystery-14529</td>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>hilarious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>2018-En-mystery-16746</td>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>2018-En-mystery-00046</td>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>2018-En-mystery-16664</td>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID                                     Sentence  \\\n",
       "0     2018-En-mystery-05498                          Alonzo feels angry.   \n",
       "1     2018-En-mystery-11722                        Alonzo feels furious.   \n",
       "2     2018-En-mystery-11364                      Alonzo feels irritated.   \n",
       "3     2018-En-mystery-14320                        Alonzo feels enraged.   \n",
       "4     2018-En-mystery-14114                        Alonzo feels annoyed.   \n",
       "...                     ...                                          ...   \n",
       "8635  2018-En-mystery-12020      The conversation with my mom was funny.   \n",
       "8636  2018-En-mystery-14529  The conversation with my mom was hilarious.   \n",
       "8637  2018-En-mystery-16746    The conversation with my mom was amazing.   \n",
       "8638  2018-En-mystery-00046  The conversation with my mom was wonderful.   \n",
       "8639  2018-En-mystery-16664      The conversation with my mom was great.   \n",
       "\n",
       "                                               Template  Person  Gender  \\\n",
       "0                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "1                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "2                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "3                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "4                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "...                                                 ...     ...     ...   \n",
       "8635  The conversation with <person object> was <emo...  my mom  female   \n",
       "8636  The conversation with <person object> was <emo...  my mom  female   \n",
       "8637  The conversation with <person object> was <emo...  my mom  female   \n",
       "8638  The conversation with <person object> was <emo...  my mom  female   \n",
       "8639  The conversation with <person object> was <emo...  my mom  female   \n",
       "\n",
       "                  Race Emotion Emotion word  \n",
       "0     African-American   anger        angry  \n",
       "1     African-American   anger      furious  \n",
       "2     African-American   anger    irritated  \n",
       "3     African-American   anger      enraged  \n",
       "4     African-American   anger      annoyed  \n",
       "...                ...     ...          ...  \n",
       "8635               NaN     joy        funny  \n",
       "8636               NaN     joy    hilarious  \n",
       "8637               NaN     joy      amazing  \n",
       "8638               NaN     joy    wonderful  \n",
       "8639               NaN     joy        great  \n",
       "\n",
       "[8640 rows x 8 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping other columns\n",
    "eec_test = eec.drop([\"ID\", \"Template\", \"Person\", \"Gender\", \"Race\", \"Emotion\", \"Emotion word\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "field Race: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-dba2a5bf4530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meec_test_spark\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_pandas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Create a DataFrame from pandas DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             return super(SparkSession, self).createDataFrame(\n\u001b[0m\u001b[1;32m    604\u001b[0m                 data, schema, samplingRatio, verifySchema)\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchemaFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    381\u001b[0m             warnings.warn(\"inferring schema from dict is deprecated,\"\n\u001b[1;32m    382\u001b[0m                           \"please use pyspark.sql.Row instead\")\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_merge_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some of types cannot be determined after inferring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_merge_type\u001b[0;34m(a, b, name)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mnfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001b[0m\u001b[1;32m   1105\u001b[0m                                                   name=new_name(f.name)))\n\u001b[1;32m   1106\u001b[0m                   for f in a.fields]\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mnfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001b[0m\u001b[1;32m   1105\u001b[0m                                                   name=new_name(f.name)))\n\u001b[1;32m   1106\u001b[0m                   for f in a.fields]\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_merge_type\u001b[0;34m(a, b, name)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# TODO: type cast (such as int -> long)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not merge type %s and %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;31m# same type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: field Race: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>"
     ]
    }
   ],
   "source": [
    "eec_test_spark= spark.createDataFrame(eec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the pandas df to a spark df\n",
    "eec_test_spark= spark.createDataFrame(eec_test)\n",
    "\n",
    "#renaming the input column as \"Sentence\" from \"text\"\n",
    "eec_test_spark = eec_test_spark.withColumnRenamed(\"sentence\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|      id|                text|               place|polarity|label|               words|            filtered|                  tf|               tfidf|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|1.29E+18|!! sigalert !! a ...|          Corona, CA|  0.1429|    1|[sigalert, a, cra...|[sigalert, crash,...|(21612,[16,47,117...|(21612,[16,47,117...|[-0.8939347319445...|[0.29029850478073...|       1.0|\n",
      "|1.29E+18|!! sigalert !! a ...|          Corona, CA|  0.1429|    1|[sigalert, a, cra...|[sigalert, crash,...|(21612,[16,47,117...|(21612,[16,47,117...|[-0.8939347319445...|[0.29029850478073...|       1.0|\n",
      "|1.29E+18|\" Winner's are ne...|  Navi Mumbai, India|  0.1841|    1|[winner, s, are, ...|[winner, s, quit,...|(21612,[1,5,109,1...|(21612,[1,5,109,1...|[-7.3258396330699...|[6.57873612618046...|       1.0|\n",
      "|1.29E+18|\"...when good men...|    Toronto, Ontario|     0.7|    1|[when, good, men,...|[good, men, emerg...|(21612,[0,2,32,10...|(21612,[0,2,32,10...|[-1.4582736106639...|[0.18873151398343...|       1.0|\n",
      "|1.29E+18|\"3,2,1\" - testing...| Manchester, England|     0.0|    0|[testing, out, my...|[testing, recent,...|(21612,[2,12,30,4...|(21612,[2,12,30,4...|[0.63791743534841...|[0.65428254242191...|       0.0|\n",
      "|1.29E+18|\"A smile is the l...| Kutorejo, Indonesia|     0.4|    1|[a, smile, is, th...|[smile, light, wi...|(21612,[3,79,90,1...|(21612,[3,79,90,1...|[-3.6170516882836...|[0.02615907790485...|       1.0|\n",
      "|1.29E+18|\"A-Frames\" with #...|   Pontnewydd, Wales|     0.0|    0|[a, frames, with,...|[frames, covid, p...|(21612,[0,47,109,...|(21612,[0,47,109,...|[0.98280738435921...|[0.72766490746122...|       0.0|\n",
      "|1.29E+18|\"ALL BALL REF‚ùó‚öΩÔ∏è?...|         Orlando, FL|     0.0|    0|[all, ball, ref, ...|[ball, ref, ybhbf...|(21612,[13,2373,2...|(21612,[13,2373,2...|[1.43034232373129...|[0.80695464816544...|       0.0|\n",
      "|1.29E+18|\"American science...|         Seattle, WA|     0.0|    0|[american, scienc...|[american, scienc...|(21612,[0,1,12,54...|(21612,[0,1,12,54...|[0.81389246597885...|[0.69293834437085...|       0.0|\n",
      "|1.29E+18|\"Analysts and ind...|Dubai, United Ara...|  0.0417|    1|[analysts, and, i...|[analysts, indust...|(21612,[1,16,47,7...|(21612,[1,16,47,7...|[1.22135358463918...|[0.77230166745459...|       0.0|\n",
      "|1.29E+18|\"Askari Bank‚Äôs Pr...|    Lahore, Pakistan|  0.0024|    1|[askari, bank, s,...|[askari, bank, s,...|(21612,[0,1,35,10...|(21612,[0,1,35,10...|[1.47430803352092...|[0.81371130297757...|       0.0|\n",
      "|1.29E+18|\"Back to work. Ba...|         Houston, TX|  0.1321|    1|[back, to, work, ...|[work, ta, work, ...|(21612,[0,1,23,63...|(21612,[0,1,23,63...|[-3.4572601623427...|[0.03055308183948...|       1.0|\n",
      "|1.29E+18|\"Being with you i...|Egmore Nungambakk...|    0.46|    1|[being, with, you...|[happiness, follo...|(21612,[25,114,15...|(21612,[25,114,15...|[-8.2970318489606...|[2.49193445525866...|       1.0|\n",
      "|1.29E+18|\"Can a Cartoon Ra...|         Seattle, WA|     0.5|    1|[can, a, cartoon,...|[cartoon, raccoon...|(21612,[0,29,970,...|(21612,[0,29,970,...|[-1.1838598243474...|[0.23435889940861...|       1.0|\n",
      "|1.29E+18|\"Closed for the f...|            Elko, NV|   0.025|    1|[closed, for, the...|[closed, foreseea...|(21612,[0,96,220,...|(21612,[0,96,220,...|[-0.7503409605067...|[0.32074701177635...|       1.0|\n",
      "|1.29E+18|\"Covid 19\" came ....|      Trissur, India|     0.0|    0|[covid, came, is,...|[covid, came, ind...|(21612,[0,1,37,43...|(21612,[0,1,37,43...|[1.45590849081750...|[0.81090609133168...|       0.0|\n",
      "|1.29E+18|\"Covid 19\" came ....|      Trissur, India|     0.0|    0|[covid, came, is,...|[covid, came, ind...|(21612,[0,1,129,3...|(21612,[0,1,129,3...|[1.45590849081750...|[0.81090609133168...|       0.0|\n",
      "|1.29E+18|\"Cum eat it üí¶\" s...|     Los Angeles, CA|  0.5333|    1|[cum, eat, it, sh...|[cum, eat, said, ...|(21612,[0,21,25,5...|(21612,[0,21,25,5...|[-5.5430006084030...|[0.00389949692331...|       1.0|\n",
      "|1.29E+18|\"Data from the CO...|      Washington, DC|  0.3333|    1|[data, from, the,...|[data, covid, sym...|(21612,[0,19,27,5...|(21612,[0,19,27,5...|[-3.0736539300050...|[0.04420718104571...|       1.0|\n",
      "|1.29E+18|\"Doing what you l...|Salug, Zamboanga ...|     0.7|    1|[doing, what, you...|[doing, like, fre...|(21612,[21,114,14...|(21612,[21,114,14...|[-1.3487394339496...|[0.20607653533505...|       1.0|\n",
      "+--------+--------------------+--------------------+--------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr_t = best_model.transform(training_df)\n",
    "predictions_lr_t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|               words|            filtered|                  tf|               tfidf|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| Alonzo feels angry.|[alonzo, feels, a...|[alonzo, feels, a...|(31661,[564,5514]...|(31661,[564,5514]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels furi...|[alonzo, feels, f...|[alonzo, feels, f...|(31661,[564,22084...|(31661,[564,22084...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels irri...|[alonzo, feels, i...|[alonzo, feels, i...|(31661,[564,20624...|(31661,[564,20624...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels enra...|[alonzo, feels, e...|[alonzo, feels, e...| (31661,[564],[1.0])|(31661,[564],[5.5...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels anno...|[alonzo, feels, a...|[alonzo, feels, a...|(31661,[564,15592...|(31661,[564,15592...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|   Alonzo feels sad.|[alonzo, feels, sad]|[alonzo, feels, sad]|(31661,[564,957],...|(31661,[564,957],...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels depr...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,7495]...|(31661,[564,7495]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels deva...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,5824]...|(31661,[564,5824]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels mise...|[alonzo, feels, m...|[alonzo, feels, m...|(31661,[564,14375...|(31661,[564,14375...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels disa...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,5811]...|(31661,[564,5811]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels terr...|[alonzo, feels, t...|[alonzo, feels, t...|(31661,[564,13061...|(31661,[564,13061...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels disc...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,23273...|(31661,[564,23273...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels scared.|[alonzo, feels, s...|[alonzo, feels, s...|(31661,[564,3012]...|(31661,[564,3012]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels anxi...|[alonzo, feels, a...|[alonzo, feels, a...|(31661,[564,3688]...|(31661,[564,3688]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels fear...|[alonzo, feels, f...|[alonzo, feels, f...|(31661,[564,14597...|(31661,[564,14597...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "| Alonzo feels happy.|[alonzo, feels, h...|[alonzo, feels, h...|(31661,[30,564],[...|(31661,[30,564],[...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels ecst...|[alonzo, feels, e...|[alonzo, feels, e...|(31661,[564,23791...|(31661,[564,23791...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|  Alonzo feels glad.|[alonzo, feels, g...|[alonzo, feels, g...|(31661,[564,730],...|(31661,[564,730],...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels reli...|[alonzo, feels, r...|[alonzo, feels, r...|(31661,[564,7988]...|(31661,[564,7988]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels exci...|[alonzo, feels, e...|[alonzo, feels, e...|(31661,[332,564],...|(31661,[332,564],...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tranforming the EEC corpus in the Best model\n",
    "predictions_lr = best_model.transform(eec_test_spark)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_raw_predictions_df = predictions_lr.select(\"text\", \"rawPrediction\",\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_raw_predictions_df = lr_raw_predictions_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# dataframe functions\n",
    "from pyspark.sql import functions as fn\n",
    "import os\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "stop_words[0:10]\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###import dataset\n",
    "\n",
    "fullDFP=pd.read_csv('fulldatasetT.csv',dtype={'polarity': float})\n",
    "fullDFP=fullDFP.loc[:,['id','text','place','polarity']]\n",
    "fullDFP['score']=0\n",
    "fullDFP.loc[fullDFP[\"polarity\"] > 0.0, 'score'] = 1\n",
    "\n",
    "mySchema = StructType([StructField(\"id\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"text\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"place\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"polarity\", FloatType(), True)\\\n",
    "                       \n",
    "                       ,StructField(\"score\", IntegerType(), True)])\n",
    "fullDf=spark.createDataFrame(fullDFP,schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df=spark.read.parquet('sentiments.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDf=fullDf.withColumnRenamed('score','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------------+--------------------+--------+------------------+\n",
      "|summary|         id|                text|               place|polarity|             label|\n",
      "+-------+-----------+--------------------+--------------------+--------+------------------+\n",
      "|  count|     151580|              151580|              151580|  151580|            151580|\n",
      "|   mean|        NaN|                 NaN|                 NaN|     NaN| 0.574548093416018|\n",
      "| stddev|        NaN|                 NaN|                 NaN|     NaN|0.4944129796127013|\n",
      "|    min|   1.27E+18| https://t.co/Xjr...|'s-Hertogenbosch,...|    -1.0|                 0|\n",
      "|    max|Rome, Lazio|ü™Ç[Everything you...|–≠–ª—å–±—Ä—É—Å—Å–∫–∏–π —Ä–∞–π–æ–Ω...|     NaN|                 1|\n",
      "+-------+-----------+--------------------+--------------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullDf.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = fullDf.randomSplit([0.6, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+\n",
      "|      word|      id|sentiment|\n",
      "+----------+--------+---------+\n",
      "|confidence|1.29E+18|        1|\n",
      "|    strong|1.29E+18|        1|\n",
      "|      nice|1.29E+18|        1|\n",
      "|      like|1.29E+18|        1|\n",
      "|protection|1.29E+18|        1|\n",
      "+----------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer().setGaps(False)\\\n",
    "  .setPattern(\"\\\\p{L}+\")\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"words\")\n",
    "review_words_df = tokenizer.transform(fullDf)\n",
    "tweet_words_sentiment_df = review_words_df.\\\n",
    "    select('id', fn.explode('words').alias('word')).\\\n",
    "    join(sentiments_df, 'word')\n",
    "tweet_words_sentiment_df.show(5)\n",
    "\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered\")\n",
    "\n",
    "# we will remove words that appear in 5 docs or less\n",
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered\")\\\n",
    "  .setOutputCol(\"tf\")\n",
    "\n",
    "# we now create a pipelined transformer\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(fullDf)\n",
    "\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('label').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)\n",
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(fullDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().setLabelCol('label').\\\n",
    "    setFeaturesCol('tfidf')\n",
    "rf_pipeline = Pipeline(stages=[idf_pipeline, rf]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705945387153658"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce = BinaryClassificationEvaluator()\n",
    "bce.evaluate(rf_pipeline.transform(validation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                          text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5558719509419924,0.44412...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5510694896786703,0.44893...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5510694896786703,0.44893...|    0|       0.0|\n",
      "|Would you like to help a bi...|[0.5510694896786703,0.44893...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_pipeline.transform(testing_df)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",'probability',\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = rf_pipeline.transform(eec_test_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|               words|            filtered|                  tf|               tfidf|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| Alonzo feels angry.|[alonzo, feels, a...|[alonzo, feels, a...|(31661,[564,5514]...|(31661,[564,5514]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels furi...|[alonzo, feels, f...|[alonzo, feels, f...|(31661,[564,22084...|(31661,[564,22084...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels irri...|[alonzo, feels, i...|[alonzo, feels, i...|(31661,[564,20624...|(31661,[564,20624...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels enra...|[alonzo, feels, e...|[alonzo, feels, e...| (31661,[564],[1.0])|(31661,[564],[5.5...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels anno...|[alonzo, feels, a...|[alonzo, feels, a...|(31661,[564,15592...|(31661,[564,15592...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|   Alonzo feels sad.|[alonzo, feels, sad]|[alonzo, feels, sad]|(31661,[564,957],...|(31661,[564,957],...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels depr...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,7495]...|(31661,[564,7495]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels deva...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,5824]...|(31661,[564,5824]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels mise...|[alonzo, feels, m...|[alonzo, feels, m...|(31661,[564,14375...|(31661,[564,14375...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels disa...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,5811]...|(31661,[564,5811]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels terr...|[alonzo, feels, t...|[alonzo, feels, t...|(31661,[564,13061...|(31661,[564,13061...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels disc...|[alonzo, feels, d...|[alonzo, feels, d...|(31661,[564,23273...|(31661,[564,23273...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels scared.|[alonzo, feels, s...|[alonzo, feels, s...|(31661,[564,3012]...|(31661,[564,3012]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels anxi...|[alonzo, feels, a...|[alonzo, feels, a...|(31661,[564,3688]...|(31661,[564,3688]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels fear...|[alonzo, feels, f...|[alonzo, feels, f...|(31661,[564,14597...|(31661,[564,14597...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "| Alonzo feels happy.|[alonzo, feels, h...|[alonzo, feels, h...|(31661,[30,564],[...|(31661,[30,564],[...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels ecst...|[alonzo, feels, e...|[alonzo, feels, e...|(31661,[564,23791...|(31661,[564,23791...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|  Alonzo feels glad.|[alonzo, feels, g...|[alonzo, feels, g...|(31661,[564,730],...|(31661,[564,730],...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels reli...|[alonzo, feels, r...|[alonzo, feels, r...|(31661,[564,7988]...|(31661,[564,7988]...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "|Alonzo feels exci...|[alonzo, feels, e...|[alonzo, feels, e...|(31661,[332,564],...|(31661,[332,564],...|[8.65560021335638...|[0.43278001066781...|       1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_raw_predictions_df = predictions_rf.select(\"text\", \"rawPrediction\",\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_raw_predictions_df = rf_raw_predictions_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_raw_predictions_df[\"id\"] = rf_raw_predictions_df.index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_raw_predictions_df[\"id\"] = lr_raw_predictions_df.index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=lr_raw_predictions_df.merge(rf_raw_predictions_df, on= \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_x</th>\n",
       "      <th>rawPrediction_x</th>\n",
       "      <th>prediction_x</th>\n",
       "      <th>id</th>\n",
       "      <th>text_y</th>\n",
       "      <th>rawPrediction_y</th>\n",
       "      <th>prediction_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[1.7587616811561602, -1.7587616811561602]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[-0.26419630122863724, 0.26419630122863724]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8636</td>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[8.325650019702103, 11.674349980297892]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[0.4793126425382578, -0.4793126425382578]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8637</td>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[-1.2568624618888387, 1.2568624618888387]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8638</td>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[8.234367928179505, 11.765632071820491]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[-1.1733344977347269, 1.1733344977347269]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8639</td>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[-1.5774363136664298, 1.5774363136664298]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[8.228839254270936, 11.771160745729063]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_x  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                                  rawPrediction_x  prediction_x    id  \\\n",
       "0       [1.7587616811561602, -1.7587616811561602]           0.0     1   \n",
       "1       [1.1883767559140832, -1.1883767559140832]           0.0     2   \n",
       "2       [1.1883767559140832, -1.1883767559140832]           0.0     3   \n",
       "3       [1.1883767559140832, -1.1883767559140832]           0.0     4   \n",
       "4       [1.1883767559140832, -1.1883767559140832]           0.0     5   \n",
       "...                                           ...           ...   ...   \n",
       "8635  [-0.26419630122863724, 0.26419630122863724]           1.0  8636   \n",
       "8636    [0.4793126425382578, -0.4793126425382578]           0.0  8637   \n",
       "8637    [-1.2568624618888387, 1.2568624618888387]           1.0  8638   \n",
       "8638    [-1.1733344977347269, 1.1733344977347269]           1.0  8639   \n",
       "8639    [-1.5774363136664298, 1.5774363136664298]           1.0  8640   \n",
       "\n",
       "                                           text_y  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                              rawPrediction_y  prediction_y  \n",
       "0     [8.655600213356383, 11.344399786643615]           1.0  \n",
       "1     [8.655600213356383, 11.344399786643615]           1.0  \n",
       "2     [8.655600213356383, 11.344399786643615]           1.0  \n",
       "3     [8.655600213356383, 11.344399786643615]           1.0  \n",
       "4     [8.655600213356383, 11.344399786643615]           1.0  \n",
       "...                                       ...           ...  \n",
       "8635  [8.325650019702103, 11.674349980297892]           1.0  \n",
       "8636  [8.655600213356383, 11.344399786643615]           1.0  \n",
       "8637  [8.234367928179505, 11.765632071820491]           1.0  \n",
       "8638  [8.655600213356383, 11.344399786643615]           1.0  \n",
       "8639  [8.228839254270936, 11.771160745729063]           1.0  \n",
       "\n",
       "[8640 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = new_df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "new_df = pd.new_df(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"new_val1\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_df)):\n",
    "    new_df.iloc[i,7]= new_df[\"rawPrediction_x\"][i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"new_val2\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_df)):\n",
    "    new_df.iloc[i,8]= new_df[\"rawPrediction_y\"][i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_x</th>\n",
       "      <th>rawPrediction_x</th>\n",
       "      <th>prediction_x</th>\n",
       "      <th>id</th>\n",
       "      <th>text_y</th>\n",
       "      <th>rawPrediction_y</th>\n",
       "      <th>prediction_y</th>\n",
       "      <th>new_val1</th>\n",
       "      <th>new_val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[1.7587616811561602, -1.7587616811561602]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.758762</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[-0.26419630122863724, 0.26419630122863724]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8636</td>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[8.325650019702103, 11.674349980297892]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.264196</td>\n",
       "      <td>8.325650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[0.4793126425382578, -0.4793126425382578]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8637</td>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479313</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[-1.2568624618888387, 1.2568624618888387]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8638</td>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[8.234367928179505, 11.765632071820491]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.256862</td>\n",
       "      <td>8.234368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[-1.1733344977347269, 1.1733344977347269]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8639</td>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.173334</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[-1.5774363136664298, 1.5774363136664298]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[8.228839254270936, 11.771160745729063]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.577436</td>\n",
       "      <td>8.228839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_x  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                                  rawPrediction_x  prediction_x    id  \\\n",
       "0       [1.7587616811561602, -1.7587616811561602]           0.0     1   \n",
       "1       [1.1883767559140832, -1.1883767559140832]           0.0     2   \n",
       "2       [1.1883767559140832, -1.1883767559140832]           0.0     3   \n",
       "3       [1.1883767559140832, -1.1883767559140832]           0.0     4   \n",
       "4       [1.1883767559140832, -1.1883767559140832]           0.0     5   \n",
       "...                                           ...           ...   ...   \n",
       "8635  [-0.26419630122863724, 0.26419630122863724]           1.0  8636   \n",
       "8636    [0.4793126425382578, -0.4793126425382578]           0.0  8637   \n",
       "8637    [-1.2568624618888387, 1.2568624618888387]           1.0  8638   \n",
       "8638    [-1.1733344977347269, 1.1733344977347269]           1.0  8639   \n",
       "8639    [-1.5774363136664298, 1.5774363136664298]           1.0  8640   \n",
       "\n",
       "                                           text_y  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                              rawPrediction_y  prediction_y  new_val1  \\\n",
       "0     [8.655600213356383, 11.344399786643615]           1.0  1.758762   \n",
       "1     [8.655600213356383, 11.344399786643615]           1.0  1.188377   \n",
       "2     [8.655600213356383, 11.344399786643615]           1.0  1.188377   \n",
       "3     [8.655600213356383, 11.344399786643615]           1.0  1.188377   \n",
       "4     [8.655600213356383, 11.344399786643615]           1.0  1.188377   \n",
       "...                                       ...           ...       ...   \n",
       "8635  [8.325650019702103, 11.674349980297892]           1.0 -0.264196   \n",
       "8636  [8.655600213356383, 11.344399786643615]           1.0  0.479313   \n",
       "8637  [8.234367928179505, 11.765632071820491]           1.0 -1.256862   \n",
       "8638  [8.655600213356383, 11.344399786643615]           1.0 -1.173334   \n",
       "8639  [8.228839254270936, 11.771160745729063]           1.0 -1.577436   \n",
       "\n",
       "      new_val2  \n",
       "0     8.655600  \n",
       "1     8.655600  \n",
       "2     8.655600  \n",
       "3     8.655600  \n",
       "4     8.655600  \n",
       "...        ...  \n",
       "8635  8.325650  \n",
       "8636  8.655600  \n",
       "8637  8.234368  \n",
       "8638  8.655600  \n",
       "8639  8.228839  \n",
       "\n",
       "[8640 rows x 9 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_to_be = new_df.loc[:, [\"new_val1\",\"new_val2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_val1</th>\n",
       "      <th>new_val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.758762</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>-0.264196</td>\n",
       "      <td>8.325650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>0.479313</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>-1.256862</td>\n",
       "      <td>8.234368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>-1.173334</td>\n",
       "      <td>8.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>-1.577436</td>\n",
       "      <td>8.228839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      new_val1  new_val2\n",
       "0     1.758762  8.655600\n",
       "1     1.188377  8.655600\n",
       "2     1.188377  8.655600\n",
       "3     1.188377  8.655600\n",
       "4     1.188377  8.655600\n",
       "...        ...       ...\n",
       "8635 -0.264196  8.325650\n",
       "8636  0.479313  8.655600\n",
       "8637 -1.256862  8.234368\n",
       "8638 -1.173334  8.655600\n",
       "8639 -1.577436  8.228839\n",
       "\n",
       "[8640 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_to_be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaler.fit_transform(new_df_to_be),columns=new_df_to_be.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_val1</th>\n",
       "      <th>new_val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524358</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>0.236106</td>\n",
       "      <td>0.226850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>0.342049</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>0.094661</td>\n",
       "      <td>0.012955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>0.106563</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>0.048983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      new_val1  new_val2\n",
       "0     0.524358  1.000000\n",
       "1     0.443084  1.000000\n",
       "2     0.443084  1.000000\n",
       "3     0.443084  1.000000\n",
       "4     0.443084  1.000000\n",
       "...        ...       ...\n",
       "8635  0.236106  0.226850\n",
       "8636  0.342049  1.000000\n",
       "8637  0.094661  0.012955\n",
       "8638  0.106563  1.000000\n",
       "8639  0.048983  0.000000\n",
       "\n",
       "[8640 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled[\"id\"] = df_scaled.index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_val1</th>\n",
       "      <th>new_val2</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>0.236106</td>\n",
       "      <td>0.226850</td>\n",
       "      <td>8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>0.342049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>0.094661</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>0.106563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>0.048983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      new_val1  new_val2    id\n",
       "0     0.524358  1.000000     1\n",
       "1     0.443084  1.000000     2\n",
       "2     0.443084  1.000000     3\n",
       "3     0.443084  1.000000     4\n",
       "4     0.443084  1.000000     5\n",
       "...        ...       ...   ...\n",
       "8635  0.236106  0.226850  8636\n",
       "8636  0.342049  1.000000  8637\n",
       "8637  0.094661  0.012955  8638\n",
       "8638  0.106563  1.000000  8639\n",
       "8639  0.048983  0.000000  8640\n",
       "\n",
       "[8640 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=new_df.merge(df_scaled, on= \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_x</th>\n",
       "      <th>rawPrediction_x</th>\n",
       "      <th>prediction_x</th>\n",
       "      <th>id</th>\n",
       "      <th>text_y</th>\n",
       "      <th>rawPrediction_y</th>\n",
       "      <th>prediction_y</th>\n",
       "      <th>new_val1_x</th>\n",
       "      <th>new_val2_x</th>\n",
       "      <th>new_val1_y</th>\n",
       "      <th>new_val2_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[1.7587616811561602, -1.7587616811561602]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.758762</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.524358</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[-0.26419630122863724, 0.26419630122863724]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8636</td>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[8.325650019702103, 11.674349980297892]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.264196</td>\n",
       "      <td>8.325650</td>\n",
       "      <td>0.236106</td>\n",
       "      <td>0.226850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[0.4793126425382578, -0.4793126425382578]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8637</td>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479313</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.342049</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[-1.2568624618888387, 1.2568624618888387]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8638</td>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[8.234367928179505, 11.765632071820491]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.256862</td>\n",
       "      <td>8.234368</td>\n",
       "      <td>0.094661</td>\n",
       "      <td>0.012955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[-1.1733344977347269, 1.1733344977347269]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8639</td>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.173334</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.106563</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[-1.5774363136664298, 1.5774363136664298]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[8.228839254270936, 11.771160745729063]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.577436</td>\n",
       "      <td>8.228839</td>\n",
       "      <td>0.048983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_x  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                                  rawPrediction_x  prediction_x    id  \\\n",
       "0       [1.7587616811561602, -1.7587616811561602]           0.0     1   \n",
       "1       [1.1883767559140832, -1.1883767559140832]           0.0     2   \n",
       "2       [1.1883767559140832, -1.1883767559140832]           0.0     3   \n",
       "3       [1.1883767559140832, -1.1883767559140832]           0.0     4   \n",
       "4       [1.1883767559140832, -1.1883767559140832]           0.0     5   \n",
       "...                                           ...           ...   ...   \n",
       "8635  [-0.26419630122863724, 0.26419630122863724]           1.0  8636   \n",
       "8636    [0.4793126425382578, -0.4793126425382578]           0.0  8637   \n",
       "8637    [-1.2568624618888387, 1.2568624618888387]           1.0  8638   \n",
       "8638    [-1.1733344977347269, 1.1733344977347269]           1.0  8639   \n",
       "8639    [-1.5774363136664298, 1.5774363136664298]           1.0  8640   \n",
       "\n",
       "                                           text_y  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                              rawPrediction_y  prediction_y  new_val1_x  \\\n",
       "0     [8.655600213356383, 11.344399786643615]           1.0    1.758762   \n",
       "1     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "2     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "3     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "4     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "...                                       ...           ...         ...   \n",
       "8635  [8.325650019702103, 11.674349980297892]           1.0   -0.264196   \n",
       "8636  [8.655600213356383, 11.344399786643615]           1.0    0.479313   \n",
       "8637  [8.234367928179505, 11.765632071820491]           1.0   -1.256862   \n",
       "8638  [8.655600213356383, 11.344399786643615]           1.0   -1.173334   \n",
       "8639  [8.228839254270936, 11.771160745729063]           1.0   -1.577436   \n",
       "\n",
       "      new_val2_x  new_val1_y  new_val2_y  \n",
       "0       8.655600    0.524358    1.000000  \n",
       "1       8.655600    0.443084    1.000000  \n",
       "2       8.655600    0.443084    1.000000  \n",
       "3       8.655600    0.443084    1.000000  \n",
       "4       8.655600    0.443084    1.000000  \n",
       "...          ...         ...         ...  \n",
       "8635    8.325650    0.236106    0.226850  \n",
       "8636    8.655600    0.342049    1.000000  \n",
       "8637    8.234368    0.094661    0.012955  \n",
       "8638    8.655600    0.106563    1.000000  \n",
       "8639    8.228839    0.048983    0.000000  \n",
       "\n",
       "[8640 rows x 11 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec[\"id\"] = eec.index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.merge(eec, on= \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_x</th>\n",
       "      <th>rawPrediction_x</th>\n",
       "      <th>prediction_x</th>\n",
       "      <th>id</th>\n",
       "      <th>text_y</th>\n",
       "      <th>rawPrediction_y</th>\n",
       "      <th>prediction_y</th>\n",
       "      <th>new_val1_x</th>\n",
       "      <th>new_val2_x</th>\n",
       "      <th>new_val1_y</th>\n",
       "      <th>new_val2_y</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Template</th>\n",
       "      <th>Person</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[1.7587616811561602, -1.7587616811561602]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.758762</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.524358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-05498</td>\n",
       "      <td>Alonzo feels angry.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-11722</td>\n",
       "      <td>Alonzo feels furious.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>furious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-11364</td>\n",
       "      <td>Alonzo feels irritated.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>irritated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-14320</td>\n",
       "      <td>Alonzo feels enraged.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>enraged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[1.1883767559140832, -1.1883767559140832]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188377</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-14114</td>\n",
       "      <td>Alonzo feels annoyed.</td>\n",
       "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
       "      <td>Alonzo</td>\n",
       "      <td>male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>anger</td>\n",
       "      <td>annoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[-0.26419630122863724, 0.26419630122863724]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8636</td>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>[8.325650019702103, 11.674349980297892]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.264196</td>\n",
       "      <td>8.325650</td>\n",
       "      <td>0.236106</td>\n",
       "      <td>0.226850</td>\n",
       "      <td>2018-En-mystery-12020</td>\n",
       "      <td>The conversation with my mom was funny.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[0.4793126425382578, -0.4793126425382578]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8637</td>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479313</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.342049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-14529</td>\n",
       "      <td>The conversation with my mom was hilarious.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>hilarious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[-1.2568624618888387, 1.2568624618888387]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8638</td>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>[8.234367928179505, 11.765632071820491]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.256862</td>\n",
       "      <td>8.234368</td>\n",
       "      <td>0.094661</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>2018-En-mystery-16746</td>\n",
       "      <td>The conversation with my mom was amazing.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[-1.1733344977347269, 1.1733344977347269]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8639</td>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>[8.655600213356383, 11.344399786643615]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.173334</td>\n",
       "      <td>8.655600</td>\n",
       "      <td>0.106563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018-En-mystery-00046</td>\n",
       "      <td>The conversation with my mom was wonderful.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[-1.5774363136664298, 1.5774363136664298]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>[8.228839254270936, 11.771160745729063]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.577436</td>\n",
       "      <td>8.228839</td>\n",
       "      <td>0.048983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-En-mystery-16664</td>\n",
       "      <td>The conversation with my mom was great.</td>\n",
       "      <td>The conversation with &lt;person object&gt; was &lt;emo...</td>\n",
       "      <td>my mom</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_x  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                                  rawPrediction_x  prediction_x    id  \\\n",
       "0       [1.7587616811561602, -1.7587616811561602]           0.0     1   \n",
       "1       [1.1883767559140832, -1.1883767559140832]           0.0     2   \n",
       "2       [1.1883767559140832, -1.1883767559140832]           0.0     3   \n",
       "3       [1.1883767559140832, -1.1883767559140832]           0.0     4   \n",
       "4       [1.1883767559140832, -1.1883767559140832]           0.0     5   \n",
       "...                                           ...           ...   ...   \n",
       "8635  [-0.26419630122863724, 0.26419630122863724]           1.0  8636   \n",
       "8636    [0.4793126425382578, -0.4793126425382578]           0.0  8637   \n",
       "8637    [-1.2568624618888387, 1.2568624618888387]           1.0  8638   \n",
       "8638    [-1.1733344977347269, 1.1733344977347269]           1.0  8639   \n",
       "8639    [-1.5774363136664298, 1.5774363136664298]           1.0  8640   \n",
       "\n",
       "                                           text_y  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                              rawPrediction_y  prediction_y  new_val1_x  \\\n",
       "0     [8.655600213356383, 11.344399786643615]           1.0    1.758762   \n",
       "1     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "2     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "3     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "4     [8.655600213356383, 11.344399786643615]           1.0    1.188377   \n",
       "...                                       ...           ...         ...   \n",
       "8635  [8.325650019702103, 11.674349980297892]           1.0   -0.264196   \n",
       "8636  [8.655600213356383, 11.344399786643615]           1.0    0.479313   \n",
       "8637  [8.234367928179505, 11.765632071820491]           1.0   -1.256862   \n",
       "8638  [8.655600213356383, 11.344399786643615]           1.0   -1.173334   \n",
       "8639  [8.228839254270936, 11.771160745729063]           1.0   -1.577436   \n",
       "\n",
       "      new_val2_x  new_val1_y  new_val2_y                     ID  \\\n",
       "0       8.655600    0.524358    1.000000  2018-En-mystery-05498   \n",
       "1       8.655600    0.443084    1.000000  2018-En-mystery-11722   \n",
       "2       8.655600    0.443084    1.000000  2018-En-mystery-11364   \n",
       "3       8.655600    0.443084    1.000000  2018-En-mystery-14320   \n",
       "4       8.655600    0.443084    1.000000  2018-En-mystery-14114   \n",
       "...          ...         ...         ...                    ...   \n",
       "8635    8.325650    0.236106    0.226850  2018-En-mystery-12020   \n",
       "8636    8.655600    0.342049    1.000000  2018-En-mystery-14529   \n",
       "8637    8.234368    0.094661    0.012955  2018-En-mystery-16746   \n",
       "8638    8.655600    0.106563    1.000000  2018-En-mystery-00046   \n",
       "8639    8.228839    0.048983    0.000000  2018-En-mystery-16664   \n",
       "\n",
       "                                         Sentence  \\\n",
       "0                             Alonzo feels angry.   \n",
       "1                           Alonzo feels furious.   \n",
       "2                         Alonzo feels irritated.   \n",
       "3                           Alonzo feels enraged.   \n",
       "4                           Alonzo feels annoyed.   \n",
       "...                                           ...   \n",
       "8635      The conversation with my mom was funny.   \n",
       "8636  The conversation with my mom was hilarious.   \n",
       "8637    The conversation with my mom was amazing.   \n",
       "8638  The conversation with my mom was wonderful.   \n",
       "8639      The conversation with my mom was great.   \n",
       "\n",
       "                                               Template  Person  Gender  \\\n",
       "0                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "1                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "2                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "3                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "4                <person subject> feels <emotion word>.  Alonzo    male   \n",
       "...                                                 ...     ...     ...   \n",
       "8635  The conversation with <person object> was <emo...  my mom  female   \n",
       "8636  The conversation with <person object> was <emo...  my mom  female   \n",
       "8637  The conversation with <person object> was <emo...  my mom  female   \n",
       "8638  The conversation with <person object> was <emo...  my mom  female   \n",
       "8639  The conversation with <person object> was <emo...  my mom  female   \n",
       "\n",
       "                  Race Emotion Emotion word  \n",
       "0     African-American   anger        angry  \n",
       "1     African-American   anger      furious  \n",
       "2     African-American   anger    irritated  \n",
       "3     African-American   anger      enraged  \n",
       "4     African-American   anger      annoyed  \n",
       "...                ...     ...          ...  \n",
       "8635               NaN     joy        funny  \n",
       "8636               NaN     joy    hilarious  \n",
       "8637               NaN     joy      amazing  \n",
       "8638               NaN     joy    wonderful  \n",
       "8639               NaN     joy        great  \n",
       "\n",
       "[8640 rows x 19 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "Sentence           0\n",
       "Template           0\n",
       "Person             0\n",
       "Gender             0\n",
       "Race            2880\n",
       "Emotion          240\n",
       "Emotion word     240\n",
       "id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eec.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
