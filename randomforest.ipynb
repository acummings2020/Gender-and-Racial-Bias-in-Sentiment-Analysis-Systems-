{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# dataframe functions\n",
    "from pyspark.sql import functions as fn\n",
    "import os\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "stop_words[0:10]\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df=spark.read.parquet('sentiments.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###import dataset\n",
    "\n",
    "fullDFP=pd.read_csv('fulldatasetT.csv',dtype={'polarity': float})\n",
    "fullDFP=fullDFP.loc[:,['id','text','place','polarity']]\n",
    "fullDFP['score']=0\n",
    "fullDFP.loc[fullDFP[\"polarity\"] > 0.0, 'score'] = 1\n",
    "\n",
    "mySchema = StructType([StructField(\"id\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"text\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"place\", StringType(), True)\\\n",
    "\n",
    "                       ,StructField(\"polarity\", FloatType(), True)\\\n",
    "                       \n",
    "                       ,StructField(\"score\", IntegerType(), True)])\n",
    "fullDf=spark.createDataFrame(fullDFP,schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDf=fullDf.withColumnRenamed('score','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+\n",
      "|      word|      id|sentiment|\n",
      "+----------+--------+---------+\n",
      "|confidence|1.29E+18|        1|\n",
      "|    strong|1.29E+18|        1|\n",
      "|      nice|1.29E+18|        1|\n",
      "|      like|1.29E+18|        1|\n",
      "|protection|1.29E+18|        1|\n",
      "+----------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer().setGaps(False)\\\n",
    "  .setPattern(\"\\\\p{L}+\")\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"words\")\n",
    "review_words_df = tokenizer.transform(fullDf)\n",
    "tweet_words_sentiment_df = review_words_df.\\\n",
    "    select('id', fn.explode('words').alias('word')).\\\n",
    "    join(sentiments_df, 'word')\n",
    "tweet_words_sentiment_df.show(5)\n",
    "\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered\")\n",
    "\n",
    "# we will remove words that appear in 5 docs or less\n",
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered\")\\\n",
    "  .setOutputCol(\"tf\")\n",
    "\n",
    "\n",
    "# we now create a pipelined transformer\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(fullDf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('label').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)\n",
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(fullDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_df, validation_df, testing_df = fullDf.randomSplit([0.6, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().setLabelCol('label').\\\n",
    "    setFeaturesCol('tfidf')\n",
    "rf_pipeline = Pipeline(stages=[idf_pipeline, rf]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------+-----+\n",
      "|      id|                text|               place|polarity|label|\n",
      "+--------+--------------------+--------------------+--------+-----+\n",
      "|1.29E+18|Yoga InstructorðŸ§˜...|       Kentucky, USA|  0.1767|    1|\n",
      "|1.29E+18|Coz a nice stroll...|Sydney, New South...|  0.3333|    1|\n",
      "|1.29E+18|NEW! #Facemasks i...|          Martinique|  0.1705|    1|\n",
      "|1.29E+18|Iâ€™m not saying Iâ€™...|           Boise, ID| -0.1356|    0|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, QuÃ©bec|     0.0|    0|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, QuÃ©bec| -0.3125|    0|\n",
      "|1.29E+18|Fighting Stigma: ...|   Mascouche, QuÃ©bec|  0.1238|    1|\n",
      "|1.29E+18|Them COVID nights...|Vandenberg Villag...|     0.0|    0|\n",
      "|1.29E+18|Shoot after post ...|Fort Tondiarpet, ...|     0.0|    0|\n",
      "|1.29E+18|BON APPETITE\n",
      "\n",
      "Eva...|     Bal Harbour, FL|  0.0111|    1|\n",
      "|1.29E+18|Been trying to ma...|       Southport, IN| -0.0429|    0|\n",
      "|1.29E+18|Been trying to ma...|       Southport, IN| -0.0429|    0|\n",
      "|1.29E+18|We are probably m...|      Tennessee, USA|  0.0606|    1|\n",
      "|1.29E+18|Great #summer nig...|        Pasadena, CA|     0.6|    1|\n",
      "|1.29E+18|Waited all day to...|         Phoenix, AZ|  0.2964|    1|\n",
      "|1.29E+18|Another new month...|  Navi Mumbai, India|  0.1811|    1|\n",
      "|1.29E+18|@ChelseaFC\n",
      "\n",
      "let's...|       Ogun, Nigeria|     0.5|    1|\n",
      "|1.29E+18|Before lockdown\n",
      "....|        Sagar, India|     0.0|    0|\n",
      "|1.29E+18|My Mamang pogi......|Manila City, Nati...|  0.0982|    1|\n",
      "|1.29E+18|Evening in Santa ...|      Santa Cruz, CA|     0.0|    0|\n",
      "+--------+--------------------+--------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7199926431076215"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce = BinaryClassificationEvaluator()\n",
    "bce.evaluate(rf_pipeline.transform(validation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Column is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c0f005651edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pd.DataFrame(list(zip(fullDf.text, rf_model.featureImportances.toArray())),\n\u001b[0m\u001b[1;32m      3\u001b[0m             columns = ['column', 'weight']).sort_values('weight')\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column is not iterable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;31m# string methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Column is not iterable"
     ]
    }
   ],
   "source": [
    "rf_model = rf_pipeline.stages[-1]\n",
    "predictions = rfModel.transform(testData)\n",
    "#pd.DataFrame(list(zip(fullDf.text, rf_model.featureImportances.toArray())),\n",
    "            #columns = ['column', 'weight']).sort_values('weight')\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Descript\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_model.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=dtc_61201871a0e8, depth=5, numNodes=29, numClasses=2, numFeatures=31663\n",
      "  If (feature 497 <= 2.7026565541855776)\n",
      "   If (feature 2 <= 0.3931518690236652)\n",
      "    If (feature 2655 <= 3.511800318041119)\n",
      "     If (feature 210 <= 2.362734946718786)\n",
      "      If (feature 455 <= 2.659089684901454)\n",
      "       Predict: 1.0\n",
      "      Else (feature 455 > 2.659089684901454)\n",
      "       Predict: 0.0\n",
      "     Else (feature 210 > 2.362734946718786)\n",
      "      Predict: 1.0\n",
      "    Else (feature 2655 > 3.511800318041119)\n",
      "     Predict: 1.0\n",
      "   Else (feature 2 > 0.3931518690236652)\n",
      "    If (feature 9 <= 1.347995539054795)\n",
      "     If (feature 3813 <= 3.7035434187358134)\n",
      "      If (feature 6511 <= 4.061106462375173)\n",
      "       Predict: 1.0\n",
      "      Else (feature 6511 > 4.061106462375173)\n",
      "       Predict: 0.0\n",
      "     Else (feature 3813 > 3.7035434187358134)\n",
      "      Predict: 0.0\n",
      "    Else (feature 9 > 1.347995539054795)\n",
      "     If (feature 2027 <= 3.3679592818152284)\n",
      "      If (feature 24825 <= 4.991482632732677)\n",
      "       Predict: 1.0\n",
      "      Else (feature 24825 > 4.991482632732677)\n",
      "       Predict: 0.0\n",
      "     Else (feature 2027 > 3.3679592818152284)\n",
      "      If (feature 2 <= 1.1794556070709956)\n",
      "       Predict: 1.0\n",
      "      Else (feature 2 > 1.1794556070709956)\n",
      "       Predict: 0.0\n",
      "  Else (feature 497 > 2.7026565541855776)\n",
      "   If (feature 188 <= 2.3098315244139522)\n",
      "    If (feature 287 <= 2.5452351068366617)\n",
      "     Predict: 1.0\n",
      "    Else (feature 287 > 2.5452351068366617)\n",
      "     If (feature 534 <= 2.756889227674536)\n",
      "      Predict: 1.0\n",
      "     Else (feature 534 > 2.756889227674536)\n",
      "      Predict: 0.0\n",
      "   Else (feature 188 > 2.3098315244139522)\n",
      "    Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_model.trees[0].toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                          text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "|I challenge you to #SaveThe...|[0.6022037189350764,0.39779...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_pipeline.transform(testing_df)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",'probability',\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################NAIVE BAYES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
